{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffcea629",
   "metadata": {
    "id": "3f92900f"
   },
   "source": [
    "## Real-time Multimodal Emotion Classification Syatem\n",
    "\n",
    "## Using multimodal data stream [EEG+EDA+RESP_BELT] \n",
    "\n",
    "## DEAP dataset\n",
    "\n",
    "# Modifications:\n",
    "\n",
    "## New ensemble approach (Reward Penalty based Weighted Ensemble [RPWE])\n",
    "\n",
    "\n",
    "## Date: 7 Oct 2021 at 10:10 AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0f80f9d",
   "metadata": {
    "id": "a1e82a32"
   },
   "outputs": [],
   "source": [
    "#============================\n",
    "# Import important libraries\n",
    "#============================\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import scipy\n",
    "import pywt\n",
    "from creme import metrics\n",
    "import time\n",
    "import datetime\n",
    "from statistics import mode\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from collections import defaultdict, Counter\n",
    "from scipy.special import expit\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from window_slider import Slider\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "\n",
    "# from skmultiflow.trees import ExtremelyFastDecisionTreeClassifier\n",
    "# from skmultiflow.meta import AdaptiveRandomForest\n",
    "\n",
    "from window_slider import Slider\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f441d2",
   "metadata": {
    "id": "ff168d67"
   },
   "outputs": [],
   "source": [
    "def calculate_entropy(list_values):\n",
    "    counter_values = Counter(list_values).most_common()\n",
    "    probabilities = [elem[1]/len(list_values) for elem in counter_values]\n",
    "    entropy=scipy.stats.entropy(probabilities)\n",
    "    return entropy\n",
    "\n",
    "def calculate_statistics(list_values):\n",
    "    n5 = np.nanpercentile(list_values, 5)\n",
    "    n25 = np.nanpercentile(list_values, 25)\n",
    "    n75 = np.nanpercentile(list_values, 75)\n",
    "    n95 = np.nanpercentile(list_values, 95)\n",
    "    median = np.nanpercentile(list_values, 50)\n",
    "    mean = np.nanmean(list_values)\n",
    "    std = np.nanstd(list_values)\n",
    "    var = np.nanvar(list_values)\n",
    "    rms = np.nanmean(np.sqrt(list_values**2))\n",
    "    return [n5, n25, n75, n95, median, mean, std, var, rms]\n",
    "\n",
    "def calculate_crossings(list_values):\n",
    "    zero_crossing_indices = np.nonzero(np.diff(np.array(list_values)> 0))[0]\n",
    "    no_zero_crossings = len(zero_crossing_indices)\n",
    "    mean_crossing_indices = np.nonzero(np.diff(np.array(list_values) > np.nanmean(list_values)))[0]\n",
    "    no_mean_crossings = len(mean_crossing_indices)\n",
    "    return [no_zero_crossings, no_mean_crossings]\n",
    "\n",
    "def get_features(list_values):    \n",
    "    list_values = list_values[0,:]\n",
    "    entropy = calculate_entropy(list_values)\n",
    "    crossings = calculate_crossings(list_values)\n",
    "    statistics = calculate_statistics(list_values)\n",
    "    return [entropy] + crossings + statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7099ef14",
   "metadata": {
    "id": "652c5538"
   },
   "outputs": [],
   "source": [
    "#======================================================\n",
    "# EDA Feature Extraction (Wavelet Features)\n",
    "#======================================================\n",
    "def extract_eda_features(raw_eda):\n",
    "    features =[]\n",
    "    EDA = raw_eda\n",
    "    list_coeff = pywt.wavedec(EDA, 'db4', level=3)\n",
    "    \n",
    "#     print(list_coeff)\n",
    "    for coeff in list_coeff:\n",
    "        features += get_features(coeff)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4967e9dd",
   "metadata": {
    "id": "fc5de9ab"
   },
   "outputs": [],
   "source": [
    "#======================================================\n",
    "# RESP BELT Feature Extraction (Wavelet Features)\n",
    "#======================================================\n",
    "\n",
    "def extract_resp_belt_features(raw_data):\n",
    "    features =[]\n",
    "    resp_belt = raw_data\n",
    "    list_coeff = pywt.wavedec(resp_belt, 'db4', level=3)\n",
    "    \n",
    "#     print(list_coeff)\n",
    "    for coeff in list_coeff:\n",
    "        features += get_features(coeff)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9faa317",
   "metadata": {
    "id": "09d8c192"
   },
   "outputs": [],
   "source": [
    "def eeg_features(raw_data):\n",
    "    ch = 0\n",
    "    features= []\n",
    "    def calculate_entropy(list_values):\n",
    "        counter_values = Counter(list_values).most_common()\n",
    "        probabilities = [elem[1]/len(list_values) for elem in counter_values]\n",
    "        entropy=scipy.stats.entropy(probabilities)\n",
    "        return entropy\n",
    "\n",
    "    def calculate_statistics(list_values):\n",
    "        median = np.nanpercentile(list_values, 50)\n",
    "        mean = np.nanmean(list_values)\n",
    "        std = np.nanstd(list_values)\n",
    "        var = np.nanvar(list_values)\n",
    "        rms = np.nanmean(np.sqrt(list_values**2))\n",
    "        return [median, mean, std, var, rms]\n",
    "\n",
    "    def get_features(list_values):    \n",
    "    #     list_values = list_values[0,:]\n",
    "        entropy = calculate_entropy(list_values)\n",
    "        statistics = calculate_statistics(list_values)\n",
    "        return [entropy] + statistics\n",
    "    \n",
    "    for i in range(raw_data.shape[0]):\n",
    "        ch_data = raw_data[i]\n",
    "        list_coeff = pywt.wavedec(ch_data, 'db4', level=5)\n",
    "        for coeff in list_coeff:\n",
    "            features += get_features(coeff)\n",
    "            \n",
    "        ch = ch+1\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c01dad3b",
   "metadata": {
    "id": "c43adf2f"
   },
   "outputs": [],
   "source": [
    "def create_model(x):\n",
    "    learning_rate = 0.05\n",
    "    sgd = tf.keras.optimizers.SGD(lr=learning_rate)\n",
    "    dim = x.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(dim)))\n",
    "    model.add(Dense(math.ceil((2/3)*dim),input_dim=dim,activation='sigmoid'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    print(model.summary())\n",
    "    model.compile(optimizer=sgd,\n",
    "                loss='mse',\n",
    "                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3494c21f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd5f3a12",
    "outputId": "29db685f-c047-4d4f-bc01-162aa026386f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with --> FFNN\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "/home/gp/Desktop/MER_arin/DEAP_data/eeg_data/1_data_DEAP.csv\n",
      "/home/gp/Desktop/MER_arin/DEAP_data/eda_data/1_GSR_data_from_DEAP.csv\n",
      "/home/gp/Desktop/MER_arin/DEAP_data/resp_data/1_Respiration_data_from_DEAP.csv\n",
      "=========================================================================\n",
      "Person: 1 Video:1\n",
      "EEG Feature shape(1, 1152):\n",
      "EDA Feature shape(1, 48):\n",
      "RESP BELT Feature shape(1, 48):\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 768)               885504    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 769       \n",
      "=================================================================\n",
      "Total params: 886,273\n",
      "Trainable params: 886,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 768)               885504    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 769       \n",
      "=================================================================\n",
      "Total params: 886,273\n",
      "Trainable params: 886,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,601\n",
      "Trainable params: 1,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,601\n",
      "Trainable params: 1,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,601\n",
      "Trainable params: 1,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,601\n",
      "Trainable params: 1,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1152) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1152), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (1, 1, 1152).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1152) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1152), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (1, 1, 1152).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1152) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1152), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (1, 1, 1152).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1152) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1152), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (1, 1, 1152).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (1, 1, 48).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (1, 1, 48).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (1, 1, 48).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (1, 1, 48).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (1, 1, 48).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (1, 1, 48).\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_train_function.<locals>.train_function at 0x7fad54fb0400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (1, 1, 48).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (1, 1, 48).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_train_function.<locals>.train_function at 0x7fad55152510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1152) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1152), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, 1, 1152).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1152) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1152), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1, 1152).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None, 1, 48).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (None, 1, 48).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (None, 1, 48).\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad75a090d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (None, 1, 48).\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad75d589d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:2\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:3\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:4\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:5\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:6\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:7\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:8\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:9\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:10\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:11\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:12\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:13\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:14\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:15\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:16\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:17\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:18\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:19\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:20\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:21\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:22\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:23\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:24\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:25\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:27\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:28\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:29\n",
      "MER model\n",
      "===============================xxxx================================\n",
      "=========================================================================\n",
      "Person: 1 Video:30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bcb499cfab3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                     \u001b[0mhist_eda_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meda_model_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_eda\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_act_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                     \u001b[0mhist_eda_aro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meda_model_aro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_eda\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_act_aro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     \u001b[0mhist_resp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp_model_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_resp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_act_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1146\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1381\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     dataset = dataset.map(\n\u001b[0;32m--> 355\u001b[0;31m         grab_batch, num_parallel_calls=tf.data.AUTOTUNE)\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;31m# Default optimizations are disabled to avoid the overhead of (unnecessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1866\u001b[0m           \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1867\u001b[0m           \u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1868\u001b[0;31m           preserve_cardinality=True)\n\u001b[0m\u001b[1;32m   1869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1870\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   5041\u001b[0m         \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5042\u001b[0m         **self._flat_structure)\n\u001b[0;32m-> 5043\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParallelMapDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5045\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, variant_tensor)\u001b[0m\n\u001b[1;32m   3799\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3801\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUnaryDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, variant_tensor)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;31m# reference cycles and making work for the garbage collector.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             lambda: weak_self._trace_variant_creation()()),  # pylint: disable=unnecessary-lambda,protected-access\n\u001b[0;32m--> 218\u001b[0;31m         name=\"_variant_tracker\")\n\u001b[0m\u001b[1;32m    219\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_track_trackable\u001b[0;34m(self, trackable, name, overwrite)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \"\"\"\n\u001b[1;32m    894\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrackable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m       raise TypeError((\"Trackable._track_trackable() passed type %s, not a \"\n\u001b[1;32m    897\u001b[0m                        \"Trackable.\") % (type(trackable),))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#================================================================\n",
    "# Initialization of different parameters and performance metrics\n",
    "#================================================================\n",
    "\n",
    "classifier = 'FFNN'\n",
    "segment_in_sec = 10 #in sec\n",
    "bucket_size = int((8064/60)*segment_in_sec)  #8064 is for 60 sec record\n",
    "overlap_count = 0\n",
    "\n",
    "init_m = 0\n",
    "indx = 0\n",
    "c=0\n",
    "ccc =0\n",
    "\n",
    "\n",
    "num_classifiers = 3 #Total number of classifiers\n",
    "w_val =np.ones(num_classifiers)/num_classifiers #Weights for valence classifiers\n",
    "w_aro =np.ones(num_classifiers)/num_classifiers #Weights for valence classifiers\n",
    "\n",
    "cBbest_val = [] #Classifiers least error for valence classsification\n",
    "cBest_aro = []  #Classifiers least error for arousal classsification\n",
    "cWorst_val = [] #Classifiers heighest error for valence classsification\n",
    "cWorst_aro = []  #Classifiers heighest error for arousal classsification\n",
    "\n",
    "beta_val = np.ones(num_classifiers)/num_classifiers\n",
    "beta_aro = np.ones(num_classifiers)/num_classifiers\n",
    "\n",
    "val_MSE = []\n",
    "aro_MSE = []\n",
    "\n",
    "\n",
    "# optimizer= 'SGD' #optimizer\n",
    "# classifier = 'RNN_RPWE'+str(optimizer)\n",
    "participant = 32\n",
    "videos = 40\n",
    "\n",
    "global eeg_emotion, eda_emotion, resp_emotion, mer_emotion, all_eta\n",
    "eeg_emotion = []\n",
    "eda_emotion = []\n",
    "resp_emotion = []\n",
    "mer_emotion = []\n",
    "\n",
    "all_eta =[]\n",
    "\n",
    "\n",
    "#================================================\n",
    "# Performance matric declaration here\n",
    "#================================================\n",
    "mer_acc_val = metrics.Accuracy() #Accuracy\n",
    "mer_f1m_val = metrics.F1() #F1 measure  \n",
    "mer_acc_aro = metrics.Accuracy() #Accuracy\n",
    "mer_f1m_aro = metrics.F1() #F1 measure\n",
    "mer_roc_val = metrics.ROCAUC()\n",
    "mer_roc_aro = metrics.ROCAUC() \n",
    "mer_mcc_val = metrics.MCC()\n",
    "mer_mcc_aro = metrics.MCC()\n",
    "\n",
    "\n",
    "eeg_acc_val = metrics.Accuracy() #Accuracy\n",
    "eeg_f1m_val = metrics.F1() #F1 measure  \n",
    "eeg_acc_aro = metrics.Accuracy() #Accuracy\n",
    "eeg_f1m_aro = metrics.F1() #F1 measure\n",
    "eeg_roc_val = metrics.ROCAUC()\n",
    "eeg_roc_aro = metrics.ROCAUC()\n",
    "eeg_mcc_val = metrics.MCC()\n",
    "eeg_mcc_aro = metrics.MCC()\n",
    "\n",
    "\n",
    "eda_acc_val = metrics.Accuracy() #Accuracy\n",
    "eda_f1m_val = metrics.F1() #F1 measure  \n",
    "eda_acc_aro = metrics.Accuracy() #Accuracy\n",
    "eda_f1m_aro = metrics.F1() #F1 measure\n",
    "eda_roc_val = metrics.ROCAUC()\n",
    "eda_roc_aro = metrics.ROCAUC()\n",
    "eda_mcc_val = metrics.MCC()\n",
    "eda_mcc_aro = metrics.MCC()\n",
    "\n",
    "\n",
    "resp_acc_val = metrics.Accuracy() #Accuracy\n",
    "resp_f1m_val = metrics.F1() #F1 measure  \n",
    "resp_acc_aro = metrics.Accuracy() #Accuracy\n",
    "resp_f1m_aro = metrics.F1() #F1 measure\n",
    "resp_roc_val = metrics.ROCAUC()\n",
    "resp_roc_aro = metrics.ROCAUC()\n",
    "resp_mcc_val = metrics.MCC()\n",
    "resp_mcc_aro = metrics.MCC()\n",
    "\n",
    "all_weights_aro = []\n",
    "all_weights_val = []\n",
    "\n",
    "\n",
    "all_history_val = []\n",
    "all_history_aro = []\n",
    "\n",
    "\n",
    "mer_cm_val  = metrics.ConfusionMatrix()\n",
    "mer_cm_aro  = metrics.ConfusionMatrix()\n",
    "\n",
    "eeg_cm_val  = metrics.ConfusionMatrix()\n",
    "eeg_cm_aro  = metrics.ConfusionMatrix()\n",
    "\n",
    "eda_cm_val  = metrics.ConfusionMatrix()\n",
    "eda_cm_aro  = metrics.ConfusionMatrix()\n",
    "  \n",
    "resp_cm_val  = metrics.ConfusionMatrix()\n",
    "resp_cm_aro  = metrics.ConfusionMatrix()\n",
    "\n",
    "\n",
    "print('Working with -->', classifier)\n",
    "#=======================================\n",
    "# MAIN Loop STARTS HERE\n",
    "#=======================================\n",
    "for ii in range(0,participant): #Main loop participant loop\n",
    "\n",
    "        p =ii+1 #participant number\n",
    "        \n",
    "        print('-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-')\n",
    "        ##===================================================\n",
    "        # EEG data read from files\n",
    "        ##===================================================\n",
    "        def eeg_data(p):\n",
    "            file_eeg = 'DEAP_data/eeg_data/'+str(p)+'_data_DEAP'+'.csv'\n",
    "            print(file_eeg)\n",
    "            eeg_sig = pd.read_csv(file_eeg,sep=',', header = None, engine='python')\n",
    "            return eeg_sig\n",
    "\n",
    "        ##===================================================\n",
    "        # EDA data read from files\n",
    "        ##===================================================\n",
    "        def eda_data(p):\n",
    "            file_eda = 'DEAP_data/eda_data/'+str(p)+'_GSR_data_from_DEAP.csv'\n",
    "            print(file_eda)\n",
    "            eda_sig = pd.read_csv(file_eda,sep=',', header = None, engine='python')\n",
    "            return eda_sig\n",
    "\n",
    "        ##===================================================\n",
    "        # Resp data read from files\n",
    "        ##===================================================\n",
    "        def resp_data(p):\n",
    "            file_resp = 'DEAP_data/resp_data/'+str(p)+'_Respiration_data_from_DEAP.csv'\n",
    "            print(file_resp)\n",
    "            resp_sig = pd.read_csv(file_resp,sep=',', header = None, engine='python')\n",
    "            return resp_sig\n",
    "        \n",
    "        #------------------------------------\n",
    "        # Once file fetched data stored here \n",
    "        #------------------------------------\n",
    "        grand_eeg = eeg_data(p)\n",
    "        grand_eda = eda_data(p)\n",
    "        grand_resp = resp_data(p)\n",
    "\n",
    "        \n",
    "        for jj in range(0,videos): #Video loop for each participants\n",
    "            v = jj+1 #Video number\n",
    "            print('=========================================================================')\n",
    "            p_v = 'Person:'+ ' ' +str(p)+ ' ' +'Video:'+str(v)\n",
    "            print(p_v)\n",
    "            \n",
    "            emotion_label =[]\n",
    "            \n",
    "            \n",
    "            ##===================================================\n",
    "            # Data read from files\n",
    "            ##===================================================\n",
    "            eeg_sig = grand_eeg.loc[grand_eeg.iloc[:,1] == v]\n",
    "            eda_sig = grand_eda.loc[grand_eda.iloc[:,1] == v]\n",
    "            resp_sig = grand_resp.loc[grand_resp.iloc[:,1] == v]\n",
    "            \n",
    "            #=================================================\n",
    "            #emotion labels (valence, arousal) mapping 0-1\n",
    "            #=================================================\n",
    "            val = eeg_sig.iloc[0,8067]\n",
    "            aro = eeg_sig.iloc[0,8068]\n",
    "            \n",
    "            #valence emotion maping 0-> low valence and 1-> high valence\n",
    "\n",
    "            if (val >5):\n",
    "                vl = 1 #high valence\n",
    "            else:\n",
    "                vl = 0 #low valence\n",
    "\n",
    "            #arousal emotion maping 0-> low arousal and 1-> high high arousal\n",
    "            if (aro >5):\n",
    "                al = 1 #high arousal\n",
    "            else:\n",
    "                al = 0 #low arousal\n",
    "                \n",
    "            y_act_val = np.array([vl])\n",
    "            y_act_aro = np.array([al]) \n",
    "            \n",
    "            #==========================================================\n",
    "            # Predicted Valence and Arousal labels list initialization\n",
    "            #==========================================================\n",
    "            eeg_val_prdt=[]\n",
    "            eeg_aro_prdt =[]\n",
    "            \n",
    "            eda_val_prdt=[]\n",
    "            eda_aro_prdt =[]\n",
    "            \n",
    "            resp_val_prdt=[]\n",
    "            resp_aro_prdt =[]\n",
    "            \n",
    "            \n",
    "            #=========================================\n",
    "            # Sliding window starts here \n",
    "            #=========================================\n",
    "            slider_eeg = Slider(bucket_size,overlap_count)\n",
    "            slider_eda = Slider(bucket_size,overlap_count)\n",
    "            slider_resp = Slider(bucket_size,overlap_count)\n",
    "            \n",
    "            eeg_sig = np.array(eeg_sig.iloc[range(0,32),range(3,8067)]) #keeping only eeg signals\n",
    "            eda_sig = np.array(eda_sig.iloc[:,range(3,8067)]) #keeping only eda signals\n",
    "            resp_sig = np.array(resp_sig.iloc[:,range(3,8067)]) #keeping only resp signals\n",
    "            \n",
    "            slider_eeg.fit(eeg_sig)\n",
    "            slider_eda.fit(eda_sig)\n",
    "            slider_resp.fit(resp_sig)\n",
    "\n",
    "            while True:\n",
    "                window_data_eeg = slider_eeg.slide()\n",
    "                window_data_eda = slider_eda.slide() \n",
    "                window_data_resp = slider_resp.slide() \n",
    "                \n",
    "                #=================================================\n",
    "                # Feature extraction from EEG\n",
    "                #=================================================\n",
    "                features_eeg = eeg_features(window_data_eeg)\n",
    "                eeg = np.array([features_eeg])  #EEG raw feature vector\n",
    "                x_eeg = preprocessing.normalize(eeg) # EEG normalized features [0,1] \n",
    "                \n",
    "                \n",
    "                #=================================================\n",
    "                # Feature extraction from EDA\n",
    "                #=================================================\n",
    "                eda_features = extract_eda_features(np.array(window_data_eda))\n",
    "                eda = np.array([eda_features]) #EDA raw feature vector\n",
    "                x_eda = preprocessing.normalize(eda) #EDA normalized features\n",
    "                \n",
    "                #=================================================\n",
    "                # Feature extraction from Resp belt\n",
    "                #=================================================\n",
    "\n",
    "                resp_features = extract_resp_belt_features(np.array(window_data_resp))\n",
    "                resp = np.array([resp_features]) #RESP BELT raw feature vector\n",
    "                x_resp = preprocessing.normalize(resp) #RESP BELT normalized features\n",
    "            \n",
    "            \n",
    "                #===================================================\n",
    "                # Model initialization\n",
    "                #===================================================\n",
    "                if init_m == 0:\n",
    "                    print('EEG Feature shape{}:'.format(x_eeg.shape))\n",
    "                    print('EDA Feature shape{}:'.format(x_eda.shape))\n",
    "                    print('RESP BELT Feature shape{}:'.format(x_resp.shape))\n",
    "\n",
    "                    #========================\n",
    "                    # For EEG data model\n",
    "                    #========================\n",
    "                    eeg_model_val = create_model(x_eeg)\n",
    "\n",
    "                    eeg_model_aro = create_model(x_eeg)\n",
    "\n",
    "                    #========================\n",
    "                    # For EDA data model\n",
    "                    #========================\n",
    "                    eda_model_val = create_model(x_eda)\n",
    "\n",
    "                    eda_model_aro = create_model(x_eda)\n",
    "\n",
    "                    #==============================\n",
    "                    # For Resp Belt data Model\n",
    "                    #==============================\n",
    "                    resp_model_val = create_model(x_resp)\n",
    "\n",
    "                    resp_model_aro = create_model(x_resp)\n",
    "\n",
    "                    init_m = init_m+1\n",
    "\n",
    "\n",
    "                #===============================================================\n",
    "                # Emotion Classification --> Valence and Arousal\n",
    "                #===============================================================\n",
    "\n",
    "                if c == 0: #For the first time model will return 0 or None\n",
    "                    tmp_eeg_val = 0\n",
    "                    tmp_eeg_aro = 0\n",
    "                    \n",
    "                    tmp_eda_val = 0\n",
    "                    tmp_eda_aro = 0\n",
    "                    \n",
    "                    tmp_resp_val = 0\n",
    "                    tmp_resp_aro = 0\n",
    "                    \n",
    "                    \n",
    "                    y_pred_val_eeg = [2]\n",
    "                    y_pred_aro_eeg = [2]\n",
    "                    \n",
    "                    y_pred_val_eda = [2]\n",
    "                    y_pred_aro_eda = [2]\n",
    "                    \n",
    "                    y_pred_val_resp = [2]\n",
    "                    y_pred_aro_resp = [2]\n",
    "                    \n",
    "                    #Fit the model once\n",
    "                    hist_eeg_val = eeg_model_val.fit(np.array([x_eeg]), y_act_val, epochs = 1, batch_size = 1, verbose=0)\n",
    "                    hist_eeg_aro = eeg_model_aro.fit(np.array([x_eeg]), y_act_aro, epochs = 1, batch_size = 1, verbose=0)\n",
    "                    \n",
    "                    hist_eda_val = eda_model_val.fit(np.array([x_eda]), y_act_val, epochs = 1, batch_size = 1, verbose=0)\n",
    "                    hist_eda_aro = eda_model_aro.fit(np.array([x_eda]), y_act_aro, epochs = 1, batch_size = 1, verbose=0)\n",
    "                    \n",
    "                    hist_resp_val = resp_model_val.fit(np.array([x_resp]), y_act_val, epochs = 1, batch_size = 1, verbose=0)\n",
    "                    hist_resp_aro = resp_model_aro.fit(np.array([x_resp]), y_act_aro, epochs = 1, batch_size = 1, verbose=0)\n",
    "                    \n",
    "                    c=c+1\n",
    "                    \n",
    "                else: \n",
    "                    \n",
    "                    tmp_eeg_val  = eeg_model_val.predict(np.array([x_eeg]))[0][0][0]\n",
    "                    tmp_eeg_aro = eeg_model_aro.predict(np.array([x_eeg]))[0][0][0]\n",
    "                    \n",
    "                    tmp_eda_val = eda_model_val.predict(np.array([x_eda]))[0][0][0]\n",
    "                    tmp_eda_aro  = eda_model_aro.predict(np.array([x_eda]))[0][0][0]\n",
    "                    \n",
    "                    tmp_resp_val = resp_model_val.predict(np.array([x_resp]))[0][0][0]\n",
    "                    tmp_resp_aro = resp_model_aro.predict(np.array([x_resp]))[0][0][0]\n",
    "                    \n",
    "                    #Binary output scaling 1 if x > 0.5 else 0\n",
    "                    y_pred_val_eeg = [1 if tmp_eeg_val > 0.5 else 0]\n",
    "                    y_pred_aro_eeg = [1 if tmp_eeg_aro > 0.5 else 0]\n",
    "                    \n",
    "                    y_pred_val_eda = [1 if tmp_eda_val > 0.5 else 0]\n",
    "                    y_pred_aro_eda = [1 if tmp_eda_aro > 0.5 else 0]\n",
    "                    \n",
    "                    y_pred_val_resp = [1 if tmp_resp_val > 0.5 else 0]\n",
    "                    y_pred_aro_resp = [1 if tmp_resp_aro > 0.5 else 0]\n",
    "                    \n",
    "                    #Fit the model once\n",
    "                    hist_eeg_val = eeg_model_val.fit(np.array([x_eeg]), y_act_val, epochs = 1, batch_size = 1, verbose=0)\n",
    "                    hist_eeg_aro = eeg_model_aro.fit(np.array([x_eeg]), y_act_aro, epochs = 1, batch_size = 1, verbose=0)\n",
    "                    \n",
    "                    hist_eda_val = eda_model_val.fit(np.array([x_eda]), y_act_val, epochs = 1, batch_size = 1, verbose=0)\n",
    "                    hist_eda_aro = eda_model_aro.fit(np.array([x_eda]), y_act_aro, epochs = 1, batch_size = 1, verbose=0)\n",
    "                    \n",
    "                    hist_resp_val = resp_model_val.fit(np.array([x_resp]), y_act_val, epochs = 1, batch_size = 1, verbose=0)\n",
    "                    hist_resp_aro = resp_model_aro.fit(np.array([x_resp]), y_act_aro, epochs = 1, batch_size = 1, verbose=0)\n",
    "                    \n",
    "                    \n",
    "\n",
    "                #===========================================\n",
    "                # Performance matric update\n",
    "                #===========================================\n",
    "                \n",
    "                #Valence classification EEG\n",
    "\n",
    "                eeg_acc_val = eeg_acc_val.update(y_act_val[0], y_pred_val_eeg[0])  # update the accuracy metric\n",
    "\n",
    "                eeg_f1m_val = eeg_f1m_val.update(y_act_val[0], y_pred_val_eeg[0]) #update f1 measure metric\n",
    "                \n",
    "                eeg_roc_val = eeg_roc_val.update(y_act_val[0], y_pred_val_eeg[0])\n",
    "                \n",
    "                eeg_mcc_val = eeg_mcc_val.update(y_act_val[0], y_pred_val_eeg[0])\n",
    "                \n",
    "                #Arousal classification EEG \n",
    "\n",
    "                eeg_acc_aro = eeg_acc_aro.update(y_act_aro[0], y_pred_aro_eeg[0])  # update the accuracy metric\n",
    "\n",
    "                eeg_f1m_aro = eeg_f1m_aro.update(y_act_aro[0], y_pred_aro_eeg[0]) #update f1 measure metric\n",
    "                \n",
    "                eeg_roc_aro = eeg_roc_aro.update(y_act_aro[0], y_pred_aro_eeg[0])\n",
    "                \n",
    "                eeg_mcc_aro = eeg_mcc_aro.update(y_act_aro[0], y_pred_aro_eeg[0])\n",
    "\n",
    "\n",
    "                #Valence classification EDA\n",
    "\n",
    "                eda_acc_val = eda_acc_val.update(y_act_val[0], y_pred_val_eda[0])  # update the accuracy metric\n",
    "\n",
    "                eda_f1m_val = eda_f1m_val.update(y_act_val[0], y_pred_val_eda[0]) #update f1 measure metric\n",
    "                \n",
    "                eda_roc_val = eda_roc_val.update(y_act_val[0], y_pred_val_eda[0])\n",
    "                \n",
    "                eda_mcc_val = eda_mcc_val.update(y_act_val[0], y_pred_val_eda[0])\n",
    "                \n",
    "\n",
    "                #Arousal classification EDA\n",
    "                \n",
    "                eda_acc_aro = eda_acc_aro.update(y_act_aro[0], y_pred_aro_eda[0])  # update the accuracy metric\n",
    "\n",
    "                eda_f1m_aro = eda_f1m_aro.update(y_act_aro[0], y_pred_aro_eda[0]) #update f1 measure metric\n",
    "                \n",
    "                eda_roc_aro = eda_roc_aro.update(y_act_aro[0], y_pred_aro_eda[0])\n",
    "                \n",
    "                eda_mcc_aro = eda_mcc_aro.update(y_act_aro[0], y_pred_aro_eda[0])\n",
    "\n",
    "                #Valence classification Resp Belt\n",
    "\n",
    "                resp_acc_val = resp_acc_val.update(y_act_val[0], y_pred_val_resp[0])  # update the accuracy metric\n",
    "\n",
    "                resp_f1m_val = resp_f1m_val.update(y_act_val[0], y_pred_val_resp[0]) #update f1 measure metric\n",
    "                \n",
    "                resp_roc_val = resp_roc_val.update(y_act_val[0], y_pred_val_resp[0])\n",
    "                \n",
    "                resp_mcc_val = resp_roc_val.update(y_act_val[0], y_pred_val_resp[0])\n",
    "                \n",
    "\n",
    "                #Arousal classification Resp Belt\n",
    "\n",
    "                resp_acc_aro = resp_acc_aro.update(y_act_aro[0], y_pred_aro_resp[0])  # update the accuracy metric\n",
    "\n",
    "                resp_f1m_aro = resp_f1m_aro.update(y_act_aro[0], y_pred_aro_resp[0]) #update f1 measure metric\n",
    "                \n",
    "                resp_roc_aro = resp_roc_aro.update(y_act_aro[0], y_pred_aro_resp[0])\n",
    "                \n",
    "                resp_mcc_aro = resp_mcc_aro.update(y_act_aro[0], y_pred_aro_resp[0])\n",
    "                \n",
    "\n",
    "                if slider_eeg.reached_end_of_list(): break\n",
    "                \n",
    "            #===================================================\n",
    "            #   Error storing and comparing Part of each models\n",
    "            #===================================================\n",
    "            \n",
    "            eeg_val_MSE = 0.5 * np.square(np.subtract(y_act_val[0],tmp_eeg_val))\n",
    "            eeg_aro_MSE = 0.5 * np.square(np.subtract(y_act_aro[0],tmp_eeg_aro))\n",
    "            \n",
    "            eda_val_MSE = 0.5 * np.square(np.subtract(y_act_val[0],tmp_eda_val))\n",
    "            eda_aro_MSE = 0.5 * np.square(np.subtract(y_act_aro[0],tmp_eda_aro))\n",
    "            \n",
    "            resp_val_MSE = 0.5 * np.square(np.subtract(y_act_val[0],tmp_resp_val))\n",
    "            resp_aro_MSE = 0.5 * np.square(np.subtract(y_act_aro[0],tmp_resp_aro))\n",
    "            \n",
    "            val_MSE = [eeg_val_MSE, eda_val_MSE, resp_val_MSE] #Valence errors \n",
    "            aro_MSE = [eeg_aro_MSE, eda_aro_MSE, resp_aro_MSE] #Arousal errors\n",
    "            \n",
    "\n",
    "            \n",
    "            #=================================================================\n",
    "            # Valence Arousal MSE Compariosn and storing in Cbest and Cworst\n",
    "            #=================================================================\n",
    "            \n",
    "            if (jj==0): #First Video\n",
    "                cBest_val = val_MSE\n",
    "                cBest_aro = aro_MSE\n",
    "                \n",
    "                cWorst_val  = val_MSE\n",
    "                cWorst_aro = aro_MSE\n",
    "                \n",
    "            else:\n",
    "                #--------------------------------------------------------------\n",
    "                # Classifiers best MSE error and worst MSE error value update\n",
    "                #-------------------------------------------------------------\n",
    "                cBest_val = np.minimum(cBest_val, val_MSE)\n",
    "                cBest_aro = np.minimum(cBest_aro, aro_MSE)\n",
    "                cWorst_val = np.maximum(cWorst_val, val_MSE)\n",
    "                cWorst_aro = np.maximum(cWorst_aro, aro_MSE)\n",
    "                \n",
    "                #-----------------------------------------\n",
    "                #Beta for calence and arousal calculation\n",
    "                #-----------------------------------------              \n",
    "                beta_val = np.true_divide(list(np.subtract(cBest_val,val_MSE)), (1+np.exp(list(np.subtract(cWorst_val,cBest_val)))))\n",
    "                beta_aro = np.true_divide(list(np.subtract(cBest_aro,aro_MSE)), (1+np.exp(list(np.subtract(cWorst_aro,cBest_aro)))))\n",
    "            \n",
    "            #============================================\n",
    "            # Controls for the first time\n",
    "            #============================================\n",
    "            if ccc ==0:\n",
    "                val_label = [0, 0, 0]\n",
    "                aro_label = [0, 0, 0] \n",
    "                ccc =ccc+1\n",
    "            else:\n",
    "                val_label = [y_pred_val_eeg[0], y_pred_val_eda[0], y_pred_val_resp[0]]\n",
    "                aro_label = [y_pred_aro_eeg[0], y_pred_aro_eda[0], y_pred_aro_resp[0]] \n",
    "            \n",
    "            \n",
    "            ##=============================\n",
    "            # Confusion Matric Calculation\n",
    "            ##=============================\n",
    "            \n",
    "            eeg_cm_val = eeg_cm_val.update(y_act_val[0], y_pred_val_eeg[0])\n",
    "            eeg_cm_aro = eeg_cm_aro.update(y_act_aro[0], y_pred_aro_eeg[0])\n",
    "            \n",
    "            eda_cm_val = eda_cm_val.update(y_act_val[0], y_pred_val_eda[0])\n",
    "            eda_cm_aro = eda_cm_aro.update(y_act_aro[0], y_pred_aro_eda[0])\n",
    "            \n",
    "            resp_cm_val = resp_cm_val.update(y_act_val[0], y_pred_val_resp[0])\n",
    "            resp_cm_varo = resp_cm_aro.update(y_act_aro[0], y_pred_aro_resp[0])            \n",
    "            \n",
    "                    \n",
    "            #====================================================================\n",
    "            # Decision label ensemble --> Reward Penalty Based Weightrd Ensemble\n",
    "            #====================================================================\n",
    "            \n",
    "#             #------------------------------------------\n",
    "#             # Valence Class ensemble\n",
    "#             #------------------------------------------\n",
    "            \n",
    "#             p_val = np.dot(val_label, w_val)\n",
    "#             mer_val = 1 if p_val > 0.5 else 0\n",
    "            \n",
    "#             #------------------------------------------\n",
    "#             # Arousal Class ensemble\n",
    "#             #------------------------------------------            \n",
    "#             p_aro = np.dot(aro_label,w_aro)\n",
    "#             mer_aro = 1 if p_aro > 0.5 else 0\n",
    "            \n",
    "            # print([val_label, aro_label])\n",
    "            # print([p_val,p_aro])\n",
    "            #============================================\n",
    "            # Weight update for Valence\n",
    "            #============================================\n",
    "            w_val = w_val + list(np.multiply(w_val,beta_val))    \n",
    "            w_val_sum = sum(w_val) #total sum of weights\n",
    "            w_val = np.array(w_val/w_val_sum) #weight rescaling\n",
    "            \n",
    "            #============================================\n",
    "            # Weight update for Arousal\n",
    "            #============================================\n",
    "            \n",
    "            w_aro = w_aro + list(np.multiply(w_aro,beta_aro))\n",
    "            w_aro_sum = sum(w_aro) #total sum of weights\n",
    "            w_aro = np.array(w_aro/w_aro_sum) #weight rescaling\n",
    "            \n",
    "            mer_val = val_label[np.argmax(w_val)] #Final Class prediction Valence\n",
    "            mer_aro = aro_label[np.argmax(w_aro)] #Final Class Prediction Valence\n",
    "            \n",
    "            all_weights_val.append(w_val)\n",
    "            all_weights_aro.append(w_aro)\n",
    "            \n",
    "            #========================================================\n",
    "            # ReMECS performance metric \n",
    "            #========================================================\n",
    "            mer_acc_val = mer_acc_val.update(y_act_val[0], mer_val)\n",
    "            mer_f1m_val = mer_f1m_val.update(y_act_val[0], mer_val)\n",
    "            mer_roc_val = mer_roc_val.update(y_act_val[0], mer_val)\n",
    "            mer_mcc_val = mer_mcc_val.update(y_act_val[0], mer_val)\n",
    "            mer_cm_val  = mer_cm_val.update(y_act_val[0], mer_val)\n",
    "            \n",
    "            mer_acc_aro = mer_acc_aro.update(y_act_aro[0], mer_aro)\n",
    "            mer_f1m_aro = mer_f1m_aro.update(y_act_aro[0], mer_aro)\n",
    "            mer_roc_aro = mer_roc_aro.update(y_act_aro[0], mer_aro)\n",
    "            mer_mcc_aro = mer_mcc_aro.update(y_act_aro[0], mer_aro)\n",
    "            mer_cm_aro  = mer_cm_aro.update(y_act_aro[0], mer_aro) \n",
    "            \n",
    "            \n",
    "            eeg_emotion.append(np.array([p,v,eeg_acc_val.get(), eeg_f1m_val.get(), eeg_roc_val.get(),eeg_mcc_val.get(),\n",
    "                                        eeg_acc_aro.get(), eeg_f1m_aro.get(),eeg_roc_aro.get(), eeg_mcc_aro.get(), \n",
    "                                        y_act_val[0], y_pred_val_eeg[0], y_act_aro[0], y_pred_aro_eeg[0]]))\n",
    "            \n",
    "            eda_emotion.append(np.array([p,v,eda_acc_val.get(), eda_f1m_val.get(), eda_roc_val.get(),eda_mcc_val.get(),\n",
    "                                        eda_acc_aro.get(), eda_f1m_aro.get(), eda_roc_aro.get(), eda_mcc_aro.get(),\n",
    "                                        y_act_val[0], y_pred_val_eda[0], y_act_aro[0], y_pred_aro_eda[0]]))\n",
    "            \n",
    "            resp_emotion.append(np.array([p,v, resp_acc_val.get(), resp_f1m_val.get(), resp_roc_val.get(), resp_mcc_val.get(),\n",
    "                                          resp_acc_aro.get(),resp_f1m_aro.get(), resp_roc_aro.get(), resp_mcc_aro.get(), \n",
    "                                          y_act_val[0], y_pred_val_resp[0], y_act_aro[0], y_pred_aro_resp[0]]))\n",
    "            \n",
    "            mer_emotion.append(np.array([p,v,mer_acc_val.get(), mer_f1m_val.get(), mer_roc_val.get(), mer_mcc_val.get(),\n",
    "                                        mer_acc_aro.get(), mer_f1m_aro.get(), mer_roc_aro.get(), mer_mcc_aro.get(), \n",
    "                                        y_act_val[0], mer_val, y_act_aro[0], mer_aro]))\n",
    "            \n",
    "            all_history_val.append(['EEG',hist_eeg_val.history['loss'][0] ,'EDA',\n",
    "                                    hist_eda_val.history['loss'][0] ,'RESP',hist_resp_val.history['loss'][0]])\n",
    "            all_history_aro.append(['EEG',hist_eeg_aro.history['loss'][0] ,'EDA',\n",
    "                                    hist_eda_aro.history['loss'][0] ,'RESP',hist_resp_aro.history['loss'][0]])\n",
    "            \n",
    "            print('MER model')\n",
    "            \n",
    "\n",
    "#             print(\"Valence Accuracy:{}\".format(round(mer_acc_val.get(),4)))\n",
    "#             print(\"Valence F1 score:{}\".format(round(mer_f1m_val.get(),4)))\n",
    "#             print(\"Valence ROC score:{}\".format(round(mer_roc_val.get(),4)))\n",
    "#             print(\"Valence MCC score:{}\".format(round(mer_mcc_val.get(),4)))\n",
    "            \n",
    "#             print(\"Arousal Accuracy:{}\".format(round(mer_acc_aro.get(),4)))\n",
    "#             print(\"Arousal F1 score:{}\".format(round(mer_f1m_aro.get(),4)))\n",
    "#             print(\"Arousal ROC score:{}\".format(round(mer_roc_aro.get(),4)))\n",
    "#             print(\"Arousal MCC score:{}\".format(round(mer_mcc_aro.get(),4)))\n",
    "            print('===============================xxxx================================')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1873ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_history_aro = pd.DataFrame(all_history_aro)\n",
    "all_history_aro.to_csv('all_error_aro.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad09a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_history_val = pd.DataFrame(all_history_val)\n",
    "all_history_val.to_csv('all_error_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf20e439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Val CM:\n",
      "             0      1\n",
      "      0    571      1\n",
      "      1      0    708\n",
      "EEG aro CM:\n",
      "             0      1\n",
      "      0    539      4\n",
      "      1      0    737\n",
      "EDA Val CM:\n",
      "             0      1\n",
      "      0    415    157\n",
      "      1    124    584\n",
      "EDA aro CM:\n",
      "             0      1\n",
      "      0    367    176\n",
      "      1    105    632\n",
      "RESP Val CM:\n",
      "             0      1\n",
      "      0    413    159\n",
      "      1    127    581\n",
      "RESP Aro CM:\n",
      "             0      1\n",
      "      0    366    177\n",
      "      1    104    633\n",
      "ReMECS Val CM:\n",
      "             0      1\n",
      "      0    571      1\n",
      "      1      1    707\n",
      "ReMECS aro CM:\n",
      "             0      1\n",
      "      0    539      4\n",
      "      1      1    736\n"
     ]
    }
   ],
   "source": [
    "print('EEG Val CM:')\n",
    "print(eeg_cm_val)\n",
    "\n",
    "print('EEG aro CM:')\n",
    "print(eeg_cm_aro)\n",
    "\n",
    "print('EDA Val CM:')\n",
    "print(eda_cm_val)\n",
    "\n",
    "print('EDA aro CM:')\n",
    "print(eda_cm_aro)\n",
    "\n",
    "print('RESP Val CM:')\n",
    "print(resp_cm_val)\n",
    "print('RESP Aro CM:')\n",
    "print(resp_cm_aro)\n",
    "\n",
    "print('ReMECS Val CM:')\n",
    "print(mer_cm_val)\n",
    "\n",
    "print('ReMECS aro CM:')\n",
    "print(mer_cm_aro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20a4933b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.333333e-01</td>\n",
       "      <td>3.333333e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.333333e-01</td>\n",
       "      <td>3.333333e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.333333e-01</td>\n",
       "      <td>3.333333e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.333333e-01</td>\n",
       "      <td>3.333333e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.357076</td>\n",
       "      <td>3.253074e-01</td>\n",
       "      <td>3.176164e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.554622e-16</td>\n",
       "      <td>4.034279e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.554144e-16</td>\n",
       "      <td>4.031681e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.554182e-16</td>\n",
       "      <td>4.031725e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.554182e-16</td>\n",
       "      <td>4.031725e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.102459e-16</td>\n",
       "      <td>3.517124e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1280 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0             1             2\n",
       "0     0.333333  3.333333e-01  3.333333e-01\n",
       "1     0.333333  3.333333e-01  3.333333e-01\n",
       "2     0.333333  3.333333e-01  3.333333e-01\n",
       "3     0.333333  3.333333e-01  3.333333e-01\n",
       "4     0.357076  3.253074e-01  3.176164e-01\n",
       "...        ...           ...           ...\n",
       "1275  1.000000  3.554622e-16  4.034279e-16\n",
       "1276  1.000000  3.554144e-16  4.031681e-16\n",
       "1277  1.000000  3.554182e-16  4.031725e-16\n",
       "1278  1.000000  3.554182e-16  4.031725e-16\n",
       "1279  1.000000  3.102459e-16  3.517124e-16\n",
       "\n",
       "[1280 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_weights_aro = pd.DataFrame(all_weights_aro)\n",
    "all_weights_val = pd.DataFrame(all_weights_val)\n",
    "all_weights_aro.to_csv('all_weights_aro.csv')\n",
    "all_weights_val.to_csv('all_weights_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60907ddf",
   "metadata": {
    "id": "JkxoUAAuq-KH"
   },
   "outputs": [],
   "source": [
    "#======================================\n",
    "# Result Save For each Classifier\n",
    "#======================================\n",
    "classifier = 'RPWE'\n",
    "filename = \"DEAP/Final_Results/\"\n",
    "fname_eeg = filename + 'all_person_EEG'+'_' +classifier+'_results.csv'\n",
    "fname_eda = filename + 'all_person_EDA'+'_' +classifier+'_results.csv'\n",
    "fname_resp = filename + 'all_person_RB'+'_' +classifier+'_results.csv'\n",
    "fname_mer = filename + 'all_person_MER'+'_' +classifier+'_results.csv'\n",
    "\n",
    "column_names = ['Person', 'Video', 'Acc_val', 'F1_val','roc_val', 'mcc_val','Acc_aro',\n",
    "                'F1_aro', 'roc_aro', 'mcc_aro', 'y_act_val', 'y_pred_val', 'y_act_aro', 'y_pred_aro']\n",
    "\n",
    "eeg_emotion = pd.DataFrame(eeg_emotion,columns = column_names)\n",
    "eda_emotion = pd.DataFrame(eda_emotion,columns = column_names)\n",
    "resp_emotion = pd.DataFrame(resp_emotion,columns = column_names)\n",
    "mer_emotion = pd.DataFrame(mer_emotion,columns = column_names)\n",
    "\n",
    "eeg_emotion.to_csv(fname_eeg)\n",
    "eda_emotion.to_csv(fname_eda)\n",
    "resp_emotion.to_csv(fname_resp)\n",
    "mer_emotion.to_csv(fname_mer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79890c33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FFNN_DEAP_2021_Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

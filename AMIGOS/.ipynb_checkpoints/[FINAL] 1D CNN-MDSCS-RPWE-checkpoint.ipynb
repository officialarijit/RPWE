{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "circular-attribute",
   "metadata": {},
   "source": [
    "## ReMECS -- Real-time Multimodal Emotion Classification Syatem\n",
    "\n",
    "## Using multimodal data stream [EEG+EDA+RESP_BELT] \n",
    "## Using 1D-CNN + SGD + One pass + Weighted Majority Voting\n",
    "\n",
    "## Modifications:\n",
    "- New Feature Set for EDA and Resp Belt. \n",
    "- Feature normalization is done.\n",
    "- RECS with other modalities (EDA + Resp Belt) is incorporated for Real-time Multimodal Emotion Classification System (ReMECS).\n",
    "- Weighted Majority Vote is used for Decision Fusion. \n",
    "\n",
    "\n",
    "## Date: 26 August 2021 at 10:10 AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abroad-colors",
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================\n",
    "# Import important libraries\n",
    "#============================\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import scipy\n",
    "import pywt\n",
    "from creme import metrics\n",
    "import time\n",
    "import datetime\n",
    "from statistics import mode\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from collections import defaultdict, Counter\n",
    "from scipy.special import expit\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from window_slider import Slider\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "blond-toronto",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_entropy(list_values):\n",
    "#     counter_values = Counter(list_values).most_common()\n",
    "#     probabilities = [elem[1]/len(list_values) for elem in counter_values]\n",
    "#     entropy=scipy.stats.entropy(probabilities)\n",
    "#     return entropy\n",
    "\n",
    "# def calculate_statistics(list_values):\n",
    "#     n5 = np.nanpercentile(list_values, 5)\n",
    "#     n25 = np.nanpercentile(list_values, 25)\n",
    "#     n75 = np.nanpercentile(list_values, 75)\n",
    "#     n95 = np.nanpercentile(list_values, 95)\n",
    "#     median = np.nanpercentile(list_values, 50)\n",
    "#     mean = np.nanmean(list_values)\n",
    "#     std = np.nanstd(list_values)\n",
    "#     var = np.nanvar(list_values)\n",
    "#     rms = np.nanmean(np.sqrt(list_values**2))\n",
    "#     return [n5, n25, n75, n95, median, mean, std, var, rms]\n",
    "\n",
    "# def calculate_crossings(list_values):\n",
    "#     zero_crossing_indices = np.nonzero(np.diff(np.array(list_values)> 0))[0]\n",
    "#     no_zero_crossings = len(zero_crossing_indices)\n",
    "#     mean_crossing_indices = np.nonzero(np.diff(np.array(list_values) > np.nanmean(list_values)))[0]\n",
    "#     no_mean_crossings = len(mean_crossing_indices)\n",
    "#     return [no_zero_crossings, no_mean_crossings]\n",
    "\n",
    "# def get_features(list_values):    \n",
    "#     list_values = list_values[0,:]\n",
    "#     entropy = calculate_entropy(list_values)\n",
    "#     crossings = calculate_crossings(list_values)\n",
    "#     statistics = calculate_statistics(list_values)\n",
    "#     return [entropy] + crossings + statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "twelve-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #======================================================\n",
    "# # EDA Feature Extraction (Wavelet Features)\n",
    "# #======================================================\n",
    "# def extract_eda_features(raw_eda):\n",
    "#     features =[]\n",
    "#     EDA = raw_eda\n",
    "#     list_coeff = pywt.wavedec(EDA, 'db4', level=3)\n",
    "    \n",
    "# #     print(list_coeff)\n",
    "#     for coeff in list_coeff:\n",
    "#         features += get_features(coeff)\n",
    "#     return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "educational-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #======================================================\n",
    "# # RESP BELT Feature Extraction (Wavelet Features)\n",
    "# #======================================================\n",
    "\n",
    "# def extract_resp_belt_features(raw_data):\n",
    "#     features =[]\n",
    "#     resp_belt = raw_data\n",
    "#     list_coeff = pywt.wavedec(resp_belt, 'db4', level=3)\n",
    "    \n",
    "# #     print(list_coeff)\n",
    "#     for coeff in list_coeff:\n",
    "#         features += get_features(coeff)\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "favorite-butterfly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eeg_features(raw_data):\n",
    "#     ch = 0\n",
    "#     features= []\n",
    "#     def calculate_entropy(list_values):\n",
    "#         counter_values = Counter(list_values).most_common()\n",
    "#         probabilities = [elem[1]/len(list_values) for elem in counter_values]\n",
    "#         entropy=scipy.stats.entropy(probabilities)\n",
    "#         return entropy\n",
    "\n",
    "#     def calculate_statistics(list_values):\n",
    "#         median = np.nanpercentile(list_values, 50)\n",
    "#         mean = np.nanmean(list_values)\n",
    "#         std = np.nanstd(list_values)\n",
    "#         var = np.nanvar(list_values)\n",
    "#         rms = np.nanmean(np.sqrt(list_values**2))\n",
    "#         return [median, mean, std, var, rms]\n",
    "\n",
    "#     def get_features(list_values):    \n",
    "#     #     list_values = list_values[0,:]\n",
    "#         entropy = calculate_entropy(list_values)\n",
    "#         statistics = calculate_statistics(list_values)\n",
    "#         return [entropy] + statistics\n",
    "    \n",
    "#     for i in range(raw_data.shape[0]):\n",
    "#         ch_data = raw_data[i]\n",
    "#         list_coeff = pywt.wavedec(ch_data, 'db4', level=5)\n",
    "#         for coeff in list_coeff:\n",
    "#             features += get_features(coeff)\n",
    "            \n",
    "#         ch = ch+1\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96e12603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================\n",
    "# 1D-CNN model\n",
    "#==================================\n",
    "def create_model(x):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=1, kernel_size=1, activation='relu', input_shape=(1,x.shape[1])))\n",
    "    model.add(Conv1D(filters=1, kernel_size=1, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.05)\n",
    "\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "constant-champion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "/home/gp/Desktop/PhD-codes/AMIGOS_data/eeg_data/1data_eeg_AMIGOS.csv\n",
      "/home/gp/Desktop/PhD-codes/AMIGOS_data/eda_data/1data_eda_AMIGOS.csv\n",
      "/home/gp/Desktop/PhD-codes/AMIGOS_data/ecg_data/1data_ecg_AMIGOS.csv\n",
      "=========================================================================\n",
      "Person: 1 Video:1\n",
      "EEG Feature shape(1, 99190):\n",
      "EDA Feature shape(1, 7085):\n",
      "ecg BELT Feature shape(1, 14170):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 100 from 1 for '{{node conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d/conv1d/ExpandDims, conv1d/conv1d/ExpandDims_1)' with input shapes: [?,1,1,99190], [1,100,99190,4].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1879\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1881\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 100 from 1 for '{{node conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d/conv1d/ExpandDims, conv1d/conv1d/ExpandDims_1)' with input shapes: [?,1,1,99190], [1,100,99190,4].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-497ce0ddbac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m# For EEG data model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0;31m#========================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                 \u001b[0meeg_model_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_eeg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0meeg_model_aro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_eeg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-7983a5263f98>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    200\u001b[0m           \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m           \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 977\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1113\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1115\u001b[0;31m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    886\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1136\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   1269\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mchannel_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv1d\u001b[0;34m(value, filters, stride, padding, use_cudnn_on_gpu, data_format, name, input, dilations)\u001b[0m\n\u001b[1;32m   2009\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   2012\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m       result = squeeze_batch_dims(\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    971\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m                   \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m                   data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[1;32m    974\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    748\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    599\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    600\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3567\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3568\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3569\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3570\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3571\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0;32m-> 2042\u001b[0;31m                                 control_input_ops, op_def)\n\u001b[0m\u001b[1;32m   2043\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pySIO/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1881\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 100 from 1 for '{{node conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d/conv1d/ExpandDims, conv1d/conv1d/ExpandDims_1)' with input shapes: [?,1,1,99190], [1,100,99190,4]."
     ]
    }
   ],
   "source": [
    "#================================================================\n",
    "# Initialization of different parameters and performance metrics\n",
    "#================================================================\n",
    "\n",
    "num_classifiers = 3 #Total number of classifiers\n",
    "w_val =np.ones(num_classifiers)/num_classifiers #Weights for valence classifiers\n",
    "w_aro =np.ones(num_classifiers)/num_classifiers #Weights for valence classifiers\n",
    "\n",
    "cBbest_val = [] #Classifiers least error for valence classsification\n",
    "cBest_aro = []  #Classifiers least error for arousal classsification\n",
    "cWorst_val = [] #Classifiers heighest error for valence classsification\n",
    "cWorst_aro = []  #Classifiers heighest error for arousal classsification\n",
    "\n",
    "beta_val = np.ones(num_classifiers)/num_classifiers\n",
    "beta_aro = np.ones(num_classifiers)/num_classifiers\n",
    "\n",
    "\n",
    "# optimizer= 'SGD' #optimizer\n",
    "# classifier = 'MLP_RPWE'+str(optimizer)\n",
    "indx = 0\n",
    "c =0\n",
    "ccc = 0\n",
    "\n",
    "participant = 40\n",
    "videos = 16\n",
    "\n",
    "global eeg_emotion, eda_emotion, ecg_emotion, mer_emotion, all_eta\n",
    "eeg_emotion = []\n",
    "eda_emotion = []\n",
    "ecg_emotion = []\n",
    "mer_emotion = []\n",
    "\n",
    "all_eta =[]\n",
    "init_m = 0\n",
    "\n",
    "#================================================\n",
    "# Performance matric declaration here\n",
    "#================================================\n",
    "mer_acc_val = metrics.Accuracy() #Accuracy\n",
    "mer_f1m_val = metrics.F1() #F1 measure  \n",
    "mer_acc_aro = metrics.Accuracy() #Accuracy\n",
    "mer_f1m_aro = metrics.F1() #F1 measure\n",
    "mer_roc_val = metrics.ROCAUC()\n",
    "mer_roc_aro = metrics.ROCAUC() \n",
    "mer_mcc_val = metrics.MCC()\n",
    "mer_mcc_aro = metrics.MCC()\n",
    "\n",
    "\n",
    "eeg_acc_val = metrics.Accuracy() #Accuracy\n",
    "eeg_f1m_val = metrics.F1() #F1 measure  \n",
    "eeg_acc_aro = metrics.Accuracy() #Accuracy\n",
    "eeg_f1m_aro = metrics.F1() #F1 measure\n",
    "eeg_roc_val = metrics.ROCAUC()\n",
    "eeg_roc_aro = metrics.ROCAUC()\n",
    "eeg_mcc_val = metrics.MCC()\n",
    "eeg_mcc_aro = metrics.MCC()\n",
    "\n",
    "\n",
    "eda_acc_val = metrics.Accuracy() #Accuracy\n",
    "eda_f1m_val = metrics.F1() #F1 measure  \n",
    "eda_acc_aro = metrics.Accuracy() #Accuracy\n",
    "eda_f1m_aro = metrics.F1() #F1 measure\n",
    "eda_roc_val = metrics.ROCAUC()\n",
    "eda_roc_aro = metrics.ROCAUC()\n",
    "eda_mcc_val = metrics.MCC()\n",
    "eda_mcc_aro = metrics.MCC()\n",
    "\n",
    "\n",
    "ecg_acc_val = metrics.Accuracy() #Accuracy\n",
    "ecg_f1m_val = metrics.F1() #F1 measure  \n",
    "ecg_acc_aro = metrics.Accuracy() #Accuracy\n",
    "ecg_f1m_aro = metrics.F1() #F1 measure\n",
    "ecg_roc_val = metrics.ROCAUC()\n",
    "ecg_roc_aro = metrics.ROCAUC()\n",
    "ecg_mcc_val = metrics.MCC()\n",
    "ecg_mcc_aro = metrics.MCC()\n",
    "\n",
    "val_MSE = []\n",
    "aro_MSE = []\n",
    "\n",
    "haha_val = []\n",
    "haha_aro = []\n",
    "\n",
    "all_weights_aro = []\n",
    "all_weights_val = []\n",
    "\n",
    "\n",
    " \n",
    "mer_cm_val  = metrics.ConfusionMatrix()\n",
    "mer_cm_aro  = metrics.ConfusionMatrix()\n",
    "\n",
    "eeg_cm_val  = metrics.ConfusionMatrix()\n",
    "eeg_cm_aro  = metrics.ConfusionMatrix()\n",
    "\n",
    "eda_cm_val  = metrics.ConfusionMatrix()\n",
    "eda_cm_aro  = metrics.ConfusionMatrix()\n",
    "  \n",
    "ecg_cm_val  = metrics.ConfusionMatrix()\n",
    "ecg_cm_aro  = metrics.ConfusionMatrix()\n",
    "\n",
    "\n",
    "    \n",
    "itr = 0 #controls the learning rate\n",
    "\n",
    "\n",
    "#=======================================\n",
    "# MAIN Loop STARTS HERE\n",
    "#=======================================\n",
    "for ii in range(0,participant):\n",
    "\n",
    "        p =ii+1 #participant number\n",
    "        \n",
    "        print('-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-')\n",
    "        ##===================================================\n",
    "        # EEG data read from files\n",
    "        ##===================================================\n",
    "        def eeg_data(p):\n",
    "            file_eeg = '/home/gp/Desktop/PhD-codes/AMIGOS_data/eeg_data/'+str(p)+'data_eeg_AMIGOS'+'.csv'\n",
    "            print(file_eeg)\n",
    "            eeg_sig = pd.read_csv(file_eeg,sep=',', header = None, engine='python')\n",
    "            return eeg_sig\n",
    "\n",
    "        ##===================================================\n",
    "        # EDA data read from files\n",
    "        ##===================================================\n",
    "        def eda_data(p):\n",
    "            file_eda = '/home/gp/Desktop/PhD-codes/AMIGOS_data/eda_data/'+str(p)+'data_eda_AMIGOS.csv'\n",
    "            print(file_eda)\n",
    "            eda_sig = pd.read_csv(file_eda,sep=',', header = None, engine='python')\n",
    "            return eda_sig\n",
    "\n",
    "        ##===================================================\n",
    "        # ECG data read from files\n",
    "        ##===================================================\n",
    "        def ecg_data(p):\n",
    "            file_ecg = '/home/gp/Desktop/PhD-codes/AMIGOS_data/ecg_data/'+str(p)+'data_ecg_AMIGOS.csv'\n",
    "            print(file_ecg)\n",
    "            ecg_sig = pd.read_csv(file_ecg,sep=',', header = None, engine='python')\n",
    "            return ecg_sig\n",
    "        \n",
    "        #------------------------------------\n",
    "        # Once file fetched data stored here \n",
    "        #------------------------------------\n",
    "        grand_eeg = eeg_data(p)\n",
    "        grand_eda = eda_data(p)\n",
    "        grand_ecg = ecg_data(p)\n",
    "\n",
    "        \n",
    "        for jj in range(0,videos):\n",
    "            v = jj+1 #Video number\n",
    "            print('=========================================================================')\n",
    "            p_v = 'Person:'+ ' ' +str(p)+ ' ' +'Video:'+str(v)\n",
    "            print(p_v)\n",
    "            \n",
    "            emotion_label =[]\n",
    "            \n",
    "            \n",
    "            ##===================================================\n",
    "            # Data read from files\n",
    "            ##===================================================\n",
    "            eeg_sig = grand_eeg.loc[grand_eeg.iloc[:,1] == v]\n",
    "            eda_sig = grand_eda.loc[grand_eda.iloc[:,1] == v]\n",
    "            ecg_sig = grand_ecg.loc[grand_ecg.iloc[:,1] == v]\n",
    "            \n",
    "            #=================================================\n",
    "            #emotion labels (valence, arousal) mapping 0-1\n",
    "            #=================================================\n",
    "            aro = eeg_sig.iloc[0,7087] #arousal \n",
    "            val = eeg_sig.iloc[0,7088] #valence\n",
    "            \n",
    "            #valence emotion maping 0-> low valence and 1-> high valence\n",
    "\n",
    "            if (val >5):\n",
    "                vl = 1 #high valence\n",
    "            else:\n",
    "                vl = 0 #low valence\n",
    "\n",
    "            #arousal emotion maping 0-> low arousal and 1-> high high arousal\n",
    "            if (aro >5):\n",
    "                al = 1 #high arousal\n",
    "            else:\n",
    "                al = 0 #low arousal\n",
    "                \n",
    "            y_act_val = np.array([vl])\n",
    "            y_act_aro = np.array([al]) \n",
    "            \n",
    "            #==========================================================\n",
    "            # Predicted Valence and Arousal labels list initialization\n",
    "            #==========================================================\n",
    "            eeg_val_prdt=[]\n",
    "            eeg_aro_prdt =[]\n",
    "            \n",
    "            eda_val_prdt=[]\n",
    "            eda_aro_prdt =[]\n",
    "            \n",
    "            ecg_val_prdt=[]\n",
    "            ecg_aro_prdt =[]\n",
    "            \n",
    "            \n",
    "            eeg_sig = np.array(eeg_sig.iloc[range(0,14),range(2,7087)]) #keeping only eeg signals\n",
    "            eda_sig = np.array(eda_sig.iloc[:,range(2,7087)]) #keeping only eda signals\n",
    "            ecg_sig = np.array(ecg_sig.iloc[range(0,2),range(2,7087)]) #keeping only ecg signals\n",
    "            \n",
    "            x_eeg = []\n",
    "            x_ecg = []\n",
    "            \n",
    "            x_eda = eda_sig\n",
    "            \n",
    "            for rr in range(0,eeg_sig.shape[0]):\n",
    "                for cc in range(0,eeg_sig.shape[1]):\n",
    "                    x_eeg.append(eeg_sig[rr,cc])\n",
    "                    \n",
    "            for rr in range(0,ecg_sig.shape[0]):\n",
    "                for cc in range(0,ecg_sig.shape[1]):\n",
    "                    x_ecg.append(ecg_sig[rr,cc])\n",
    "                    \n",
    "            x_eeg = np.array([x_eeg])\n",
    "            x_ecg = np.array([x_ecg])\n",
    "            \n",
    "            \n",
    "            #===================================================\n",
    "            # Model initialization\n",
    "            #===================================================\n",
    "            if init_m == 0:\n",
    "                print('EEG Feature shape{}:'.format(x_eeg.shape))\n",
    "                print('EDA Feature shape{}:'.format(x_eda.shape))\n",
    "                print('ecg BELT Feature shape{}:'.format(x_ecg.shape))\n",
    "\n",
    "                #========================\n",
    "                # For EEG data model\n",
    "                #========================\n",
    "                eeg_model_val = create_model(x_eeg)\n",
    "\n",
    "                eeg_model_aro = create_model(x_eeg)\n",
    "\n",
    "                #========================\n",
    "                # For EDA data model\n",
    "                #========================\n",
    "                eda_model_val = create_model(x_eda)\n",
    "\n",
    "                eda_model_aro = create_model(x_eda)\n",
    "\n",
    "                #==============================\n",
    "                # For ecg Belt data Model\n",
    "                #==============================\n",
    "                ecg_model_val = create_model(x_ecg)\n",
    "\n",
    "                ecg_model_aro = create_model(x_ecg)\n",
    "\n",
    "                init_m = init_m+1\n",
    "\n",
    "\n",
    "            #===============================================================\n",
    "            # Emotion Classification --> Valence and Arousal\n",
    "            #===============================================================\n",
    "\n",
    "            if c == 0: #For the first time model will return 0 or None\n",
    "                tmp_eeg_val = 0\n",
    "                tmp_eeg_aro = 0\n",
    "\n",
    "                tmp_eda_val = 0\n",
    "                tmp_eda_aro = 0\n",
    "\n",
    "                tmp_ecg_val = 0\n",
    "                tmp_ecg_aro = 0\n",
    "\n",
    "\n",
    "                y_pred_val_eeg = [2]\n",
    "                y_pred_aro_eeg = [2]\n",
    "\n",
    "                y_pred_val_eda = [2]\n",
    "                y_pred_aro_eda = [2]\n",
    "\n",
    "                y_pred_val_ecg = [2]\n",
    "                y_pred_aro_ecg = [2]\n",
    "\n",
    "                eeg_model_val.fit(np.array([x_eeg]) , y_act_val, epochs = 1, batch_size = 1, verbose=0)\n",
    "                eeg_model_aro.fit(np.array([x_eeg]), y_act_aro, epochs = 1, batch_size = 1, verbose=0)\n",
    "\n",
    "                eda_model_val.fit(np.array([x_eda]) , y_act_val, epochs = 1, batch_size = 1, verbose=0)\n",
    "                eda_model_aro.fit(np.array([x_eda]), y_act_aro, epochs = 1, batch_size = 1, verbose=0)\n",
    "\n",
    "                ecg_model_val.fit(np.array([x_ecg]) , y_act_val, epochs = 1, batch_size = 1, verbose=0)\n",
    "                ecg_model_aro.fit(np.array([x_ecg]), y_act_aro, epochs = 1, batch_size = 1, verbose=0)\n",
    "\n",
    "                c=c+1\n",
    "\n",
    "            else: \n",
    "\n",
    "                tmp_eeg_val  = eeg_model_val.predict(np.array([x_eeg]))[0][0]\n",
    "                tmp_eeg_aro = eeg_model_aro.predict(np.array([x_eeg]))[0][0]\n",
    "\n",
    "                tmp_eda_val = eda_model_val.predict(np.array([x_eda]))[0][0]\n",
    "                tmp_eda_aro  = eda_model_aro.predict(np.array([x_eda]))[0][0]\n",
    "\n",
    "                tmp_ecg_val = ecg_model_val.predict(np.array([x_ecg]))[0][0]\n",
    "                tmp_ecg_aro = ecg_model_aro.predict(np.array([x_ecg]))[0][0]\n",
    "\n",
    "                #Binary output scaling 1 if x > 0.5 else 0\n",
    "                y_pred_val_eeg = [1 if tmp_eeg_val > 0.5 else 0]\n",
    "                y_pred_aro_eeg = [1 if tmp_eeg_aro > 0.5 else 0]\n",
    "\n",
    "                y_pred_val_eda = [1 if tmp_eda_val > 0.5 else 0]\n",
    "                y_pred_aro_eda = [1 if tmp_eda_aro > 0.5 else 0]\n",
    "\n",
    "                y_pred_val_ecg = [1 if tmp_ecg_val > 0.5 else 0]\n",
    "                y_pred_aro_ecg = [1 if tmp_ecg_aro > 0.5 else 0]\n",
    "\n",
    "                #Fit the model once\n",
    "                eeg_model_val.fit(np.array([x_eeg]), y_act_val, epochs = 1, batch_size = 1, verbose=0)\n",
    "                eeg_model_aro.fit(np.array([x_eeg]), y_act_aro, epochs = 1, batch_size = 1, verbose=0)\n",
    "\n",
    "                eda_model_val.fit(np.array([x_eda]), y_act_val, epochs = 1, batch_size = 1, verbose=0)\n",
    "                eda_model_aro.fit(np.array([x_eda]), y_act_aro, epochs = 1, batch_size = 1, verbose=0)\n",
    "\n",
    "                ecg_model_val.fit(np.array([x_ecg]), y_act_val, epochs = 1, batch_size = 1, verbose=0)\n",
    "                ecg_model_aro.fit(np.array([x_ecg]), y_act_aro, epochs = 1, batch_size = 1, verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "            #===========================================\n",
    "            # Performance matric update\n",
    "            #===========================================\n",
    "\n",
    "            #Valence classification EEG\n",
    "\n",
    "            eeg_acc_val = eeg_acc_val.update(y_act_val[0], y_pred_val_eeg[0])  # update the accuracy metric\n",
    "\n",
    "            eeg_f1m_val = eeg_f1m_val.update(y_act_val[0], y_pred_val_eeg[0]) #update f1 measure metric\n",
    "\n",
    "            eeg_roc_val = eeg_roc_val.update(y_act_val[0], y_pred_val_eeg[0])\n",
    "\n",
    "            eeg_mcc_val = eeg_mcc_val.update(y_act_val[0], y_pred_val_eeg[0])\n",
    "\n",
    "            #Arousal classification EEG \n",
    "\n",
    "            eeg_acc_aro = eeg_acc_aro.update(y_act_aro[0], y_pred_aro_eeg[0])  # update the accuracy metric\n",
    "\n",
    "            eeg_f1m_aro = eeg_f1m_aro.update(y_act_aro[0], y_pred_aro_eeg[0]) #update f1 measure metric\n",
    "\n",
    "            eeg_roc_aro = eeg_roc_aro.update(y_act_aro[0], y_pred_aro_eeg[0])\n",
    "\n",
    "            eeg_mcc_aro = eeg_mcc_aro.update(y_act_aro[0], y_pred_aro_eeg[0])\n",
    "\n",
    "\n",
    "            #Valence classification EDA\n",
    "\n",
    "            eda_acc_val = eda_acc_val.update(y_act_val[0], y_pred_val_eda[0])  # update the accuracy metric\n",
    "\n",
    "            eda_f1m_val = eda_f1m_val.update(y_act_val[0], y_pred_val_eda[0]) #update f1 measure metric\n",
    "\n",
    "            eda_roc_val = eda_roc_val.update(y_act_val[0], y_pred_val_eda[0])\n",
    "\n",
    "            eda_mcc_val = eda_mcc_val.update(y_act_val[0], y_pred_val_eda[0])\n",
    "\n",
    "\n",
    "            #Arousal classification EDA\n",
    "\n",
    "            eda_acc_aro = eda_acc_aro.update(y_act_aro[0], y_pred_aro_eda[0])  # update the accuracy metric\n",
    "\n",
    "            eda_f1m_aro = eda_f1m_aro.update(y_act_aro[0], y_pred_aro_eda[0]) #update f1 measure metric\n",
    "\n",
    "            eda_roc_aro = eda_roc_aro.update(y_act_aro[0], y_pred_aro_eda[0])\n",
    "\n",
    "            eda_mcc_aro = eda_mcc_aro.update(y_act_aro[0], y_pred_aro_eda[0])\n",
    "\n",
    "            #Valence classification ecg Belt\n",
    "\n",
    "            ecg_acc_val = ecg_acc_val.update(y_act_val[0], y_pred_val_ecg[0])  # update the accuracy metric\n",
    "\n",
    "            ecg_f1m_val = ecg_f1m_val.update(y_act_val[0], y_pred_val_ecg[0]) #update f1 measure metric\n",
    "\n",
    "            ecg_roc_val = ecg_roc_val.update(y_act_val[0], y_pred_val_ecg[0])\n",
    "\n",
    "            ecg_mcc_val = ecg_roc_val.update(y_act_val[0], y_pred_val_ecg[0])\n",
    "\n",
    "\n",
    "            #Arousal classification ecg Belt\n",
    "\n",
    "            ecg_acc_aro = ecg_acc_aro.update(y_act_aro[0], y_pred_aro_ecg[0])  # update the accuracy metric\n",
    "\n",
    "            ecg_f1m_aro = ecg_f1m_aro.update(y_act_aro[0], y_pred_aro_ecg[0]) #update f1 measure metric\n",
    "\n",
    "            ecg_roc_aro = ecg_roc_aro.update(y_act_aro[0], y_pred_aro_ecg[0])\n",
    "\n",
    "            ecg_mcc_aro = ecg_mcc_aro.update(y_act_aro[0], y_pred_aro_ecg[0])\n",
    "\n",
    "                \n",
    "            #===================================================\n",
    "            #   Error storing and comparing Part of each models\n",
    "            #===================================================\n",
    "            \n",
    "            eeg_val_MSE = 0.5 * np.square(np.subtract(y_act_val[0],tmp_eeg_val))\n",
    "            eeg_aro_MSE = 0.5 * np.square(np.subtract(y_act_aro[0],tmp_eeg_aro))\n",
    "            \n",
    "            eda_val_MSE = 0.5 * np.square(np.subtract(y_act_val[0],tmp_eda_val))\n",
    "            eda_aro_MSE = 0.5 * np.square(np.subtract(y_act_aro[0],tmp_eda_aro))\n",
    "            \n",
    "            ecg_val_MSE = 0.5 * np.square(np.subtract(y_act_val[0],tmp_ecg_val))\n",
    "            ecg_aro_MSE = 0.5 * np.square(np.subtract(y_act_aro[0],tmp_ecg_aro))\n",
    "            \n",
    "            val_MSE = [eeg_val_MSE, eda_val_MSE, ecg_val_MSE] #Valence errors \n",
    "            aro_MSE = [eeg_aro_MSE, eda_aro_MSE, ecg_aro_MSE] #Arousal errors\n",
    "            \n",
    "\n",
    "            \n",
    "            #=================================================================\n",
    "            # Valence Arousal MSE Compariosn and storing in Cbest and Cworst\n",
    "            #=================================================================\n",
    "            \n",
    "            if (jj==0): #First Video\n",
    "                cBest_val = val_MSE\n",
    "                cBest_aro = aro_MSE\n",
    "                \n",
    "                cWorst_val  = val_MSE\n",
    "                cWorst_aro = aro_MSE\n",
    "                \n",
    "            else:\n",
    "                #--------------------------------------------------------------\n",
    "                # Classifiers best MSE error and worst MSE error value update\n",
    "                #-------------------------------------------------------------\n",
    "                cBest_val = np.minimum(cBest_val, val_MSE)\n",
    "                cBest_aro = np.minimum(cBest_aro, aro_MSE)\n",
    "                cWorst_val = np.maximum(cWorst_val, val_MSE)\n",
    "                cWorst_aro = np.maximum(cWorst_aro, aro_MSE)\n",
    "                \n",
    "                #-----------------------------------------\n",
    "                #Beta for calence and arousal calculation\n",
    "                #-----------------------------------------              \n",
    "                beta_val = np.true_divide(list(np.subtract(cBest_val,val_MSE)), (1+np.exp(list(np.subtract(cWorst_val,cBest_val)))))\n",
    "                beta_aro = np.true_divide(list(np.subtract(cBest_aro,aro_MSE)), (1+np.exp(list(np.subtract(cWorst_aro,cBest_aro)))))\n",
    "            \n",
    "            #============================================\n",
    "            # Controls for the first time\n",
    "            #============================================\n",
    "            if ccc ==0:\n",
    "                val_label = [2, 2, 2]\n",
    "                aro_label = [2, 2, 2] \n",
    "                ccc =ccc+1\n",
    "            else:\n",
    "                val_label = [tmp_eeg_val, tmp_eda_val, tmp_ecg_val]\n",
    "                aro_label = [tmp_eeg_aro, tmp_eda_aro, tmp_ecg_aro] \n",
    "            \n",
    "            \n",
    "            ##=============================\n",
    "            # Confusion Matric Calculation\n",
    "            ##=============================\n",
    "            \n",
    "            eeg_cm_val = eeg_cm_val.update(y_act_val[0], y_pred_val_eeg[0])\n",
    "            eeg_cm_aro = eeg_cm_aro.update(y_act_aro[0], y_pred_aro_eeg[0])\n",
    "            \n",
    "            eda_cm_val = eda_cm_val.update(y_act_val[0], y_pred_val_eda[0])\n",
    "            eda_cm_aro = eda_cm_aro.update(y_act_aro[0], y_pred_aro_eda[0])\n",
    "            \n",
    "            ecg_cm_val = ecg_cm_val.update(y_act_val[0], y_pred_val_ecg[0])\n",
    "            ecg_cm_varo = ecg_cm_aro.update(y_act_aro[0], y_pred_aro_ecg[0])            \n",
    "            \n",
    "                    \n",
    "            #====================================================================\n",
    "            # Decision label ensemble --> Reward Penalty Based Weightrd Ensemble\n",
    "            #====================================================================\n",
    "            \n",
    "            #------------------------------------------\n",
    "            # Valence Class ensemble\n",
    "            #------------------------------------------\n",
    "            \n",
    "            p_val = np.dot(val_label, w_val)\n",
    "            mer_val = 1 if p_val > 0.5 else 0\n",
    "            \n",
    "            #------------------------------------------\n",
    "            # Arousal Class ensemble\n",
    "            #------------------------------------------            \n",
    "            p_aro = np.dot(aro_label,w_aro)\n",
    "            mer_aro = 1 if p_aro > 0.5 else 0\n",
    "            \n",
    "#             print([val_label, aro_label])\n",
    "#             print([p_val,p_aro])\n",
    "            #============================================\n",
    "            # Weight update for Valence\n",
    "            #============================================\n",
    "            w_val = w_val + list(np.multiply(w_val,beta_val))    \n",
    "            w_val_sum = sum(w_val) #total sum of weights\n",
    "            w_val = np.array(w_val/w_val_sum) #weight rescaling\n",
    "            \n",
    "            #============================================\n",
    "            # Weight update for Arousal\n",
    "            #============================================\n",
    "            \n",
    "            w_aro = w_aro + list(np.multiply(w_aro,beta_aro))\n",
    "            w_aro_sum = sum(w_aro) #total sum of weights\n",
    "            w_aro = np.array(w_aro/w_aro_sum) #weight rescaling\n",
    "            \n",
    "            all_weights_val.append(w_val)\n",
    "            all_weights_aro.append(w_aro)\n",
    "            \n",
    "#             mer_val = val_label[np.argmax(w_val)] #Final Class prediction Valence\n",
    "#             mer_aro = aro_label[np.argmax(w_aro)] #Final Class Prediction Valence\n",
    "            \n",
    "            #========================================================\n",
    "            # ReMECS performance metric \n",
    "            #========================================================\n",
    "            mer_acc_val = mer_acc_val.update(y_act_val[0], mer_val)\n",
    "            mer_f1m_val = mer_f1m_val.update(y_act_val[0], mer_val)\n",
    "            mer_roc_val = mer_roc_val.update(y_act_val[0], mer_val)\n",
    "            mer_mcc_val = mer_mcc_val.update(y_act_val[0], mer_val)\n",
    "            mer_cm_val  = mer_cm_val.update(y_act_val[0], mer_val)\n",
    "            \n",
    "            mer_acc_aro = mer_acc_aro.update(y_act_aro[0], mer_aro)\n",
    "            mer_f1m_aro = mer_f1m_aro.update(y_act_aro[0], mer_aro)\n",
    "            mer_roc_aro = mer_roc_aro.update(y_act_aro[0], mer_aro)\n",
    "            mer_mcc_aro = mer_mcc_aro.update(y_act_aro[0], mer_aro)\n",
    "            mer_cm_aro  = mer_cm_aro.update(y_act_aro[0], mer_aro) \n",
    "            \n",
    "            \n",
    "            eeg_emotion.append(np.array([p,v,eeg_acc_val.get(), eeg_f1m_val.get(), eeg_roc_val.get(),eeg_mcc_val.get(),\n",
    "                                        eeg_acc_aro.get(), eeg_f1m_aro.get(),eeg_roc_aro.get(), eeg_mcc_aro.get(), \n",
    "                                        y_act_val[0], y_pred_val_eeg[0], y_act_aro[0], y_pred_aro_eeg[0]]))\n",
    "            \n",
    "            eda_emotion.append(np.array([p,v,eda_acc_val.get(), eda_f1m_val.get(), eda_roc_val.get(),eda_mcc_val.get(),\n",
    "                                        eda_acc_aro.get(), eda_f1m_aro.get(), eda_roc_aro.get(), eda_mcc_aro.get(),\n",
    "                                        y_act_val[0], y_pred_val_eda[0], y_act_aro[0], y_pred_aro_eda[0]]))\n",
    "            \n",
    "            ecg_emotion.append(np.array([p,v, ecg_acc_val.get(), ecg_f1m_val.get(), ecg_roc_val.get(), ecg_mcc_val.get(),\n",
    "                                          ecg_acc_aro.get(),ecg_f1m_aro.get(), ecg_roc_aro.get(), ecg_mcc_aro.get(), \n",
    "                                          y_act_val[0], y_pred_val_ecg[0], y_act_aro[0], y_pred_aro_ecg[0]]))\n",
    "            \n",
    "            mer_emotion.append(np.array([p,v,mer_acc_val.get(), mer_f1m_val.get(), mer_roc_val.get(), mer_mcc_val.get(),\n",
    "                                        mer_acc_aro.get(), mer_f1m_aro.get(), mer_roc_aro.get(), mer_mcc_aro.get(), \n",
    "                                        y_act_val[0], mer_val, y_act_aro[0], mer_aro]))\n",
    "            \n",
    "            print('MER model')\n",
    "\n",
    "            print(\"Valence Accuracy:{}\".format(round(mer_acc_val.get(),4)))\n",
    "            print(\"Valence F1 score:{}\".format(round(mer_f1m_val.get(),4)))\n",
    "            print(\"Valence ROC score:{}\".format(round(mer_roc_val.get(),4)))\n",
    "            print(\"Valence MCC score:{}\".format(round(mer_mcc_val.get(),4)))\n",
    "            \n",
    "            print(\"Arousal Accuracy:{}\".format(round(mer_acc_aro.get(),4)))\n",
    "            print(\"Arousal F1 score:{}\".format(round(mer_f1m_aro.get(),4)))\n",
    "            print(\"Arousal ROC score:{}\".format(round(mer_roc_aro.get(),4)))\n",
    "            print(\"Arousal MCC score:{}\".format(round(mer_mcc_aro.get(),4)))\n",
    "            print('===============================xxxx================================')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "military-botswana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Val CM:\n",
      "             0      1\n",
      "      0    297    275\n",
      "      1    164    544\n",
      "EEG aro CM:\n",
      "             0      1\n",
      "      0    140    403\n",
      "      1    318    419\n",
      "EDA Val CM:\n",
      "             0      1\n",
      "      0    295    277\n",
      "      1    162    546\n",
      "EDA aro CM:\n",
      "             0      1\n",
      "      0    139    404\n",
      "      1    318    419\n",
      "RESP Val CM:\n",
      "             0      1\n",
      "      0    296    276\n",
      "      1    162    546\n",
      "RESP Aro CM:\n",
      "             0      1\n",
      "      0    139    404\n",
      "      1    318    419\n",
      "ReMECS Val CM:\n",
      "             0      1\n",
      "      0    296    276\n",
      "      1    163    545\n",
      "ReMECS aro CM:\n",
      "             0      1\n",
      "      0    139    404\n",
      "      1    318    419\n"
     ]
    }
   ],
   "source": [
    "print('EEG Val CM:')\n",
    "print(eeg_cm_val)\n",
    "\n",
    "print('EEG aro CM:')\n",
    "print(eeg_cm_aro)\n",
    "\n",
    "print('EDA Val CM:')\n",
    "print(eda_cm_val)\n",
    "\n",
    "print('EDA aro CM:')\n",
    "print(eda_cm_aro)\n",
    "\n",
    "print('RESP Val CM:')\n",
    "print(resp_cm_val)\n",
    "print('RESP Aro CM:')\n",
    "print(resp_cm_aro)\n",
    "\n",
    "print('ReMECS Val CM:')\n",
    "print(mer_cm_val)\n",
    "\n",
    "print('ReMECS aro CM:')\n",
    "print(mer_cm_aro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01bfe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[acc_val,f1m_val,roc_val,mcc_val,acc_aro,f1m_aro,roc_aro,mcc_aro]')\n",
    "#=============================\n",
    "# EEG\n",
    "#=============================\n",
    "t_eeg_emotion =pd.DataFrame(eeg_emotion) \n",
    "t_eeg_emotion = t_eeg_emotion.iloc[:,range(2,10)]\n",
    "t_eeg_emotion_avg = np.array(np.mean(t_eeg_emotion))\n",
    "t_eeg_emotion_std = np.array(np.std(t_eeg_emotion))\n",
    "\n",
    "print('EEG result Average:', t_eeg_emotion_avg)\n",
    "print('EEG result std:', t_eeg_emotion_std)\n",
    "\n",
    "#=============================\n",
    "# EDA\n",
    "#=============================\n",
    "t_eda_emotion =pd.DataFrame(eda_emotion) \n",
    "t_eda_emotion = t_eda_emotion.iloc[:,range(2,10)]\n",
    "t_eda_emotion_avg = np.array(np.mean(t_eda_emotion))\n",
    "t_eda_emotion_std = np.array(np.std(t_eda_emotion))\n",
    "\n",
    "print('EDA result Average:', t_eda_emotion_avg)\n",
    "print('EDA result std:', t_eda_emotion_std)\n",
    "#=============================\n",
    "# RESP BELT\n",
    "#=============================\n",
    "t_resp_emotion =pd.DataFrame(resp_emotion) \n",
    "t_resp_emotion = t_resp_emotion.iloc[:,range(2,10)]\n",
    "t_resp_emotion_avg = np.array(np.mean(t_resp_emotion))\n",
    "t_resp_emotion_std = np.array(np.std(t_resp_emotion))\n",
    "\n",
    "print('Resp Belt result Average:', t_resp_emotion_avg)\n",
    "print('Resp Belt result std:', t_resp_emotion_std)\n",
    "#=============================\n",
    "# MER\n",
    "#=============================\n",
    "t_mer_emotion =pd.DataFrame(mer_emotion) \n",
    "t_mer_emotion = t_mer_emotion.iloc[:,range(2,10)]\n",
    "t_mer_emotion_avg = np.array(np.mean(t_mer_emotion))\n",
    "t_mer_emotion_std = np.array(np.std(t_mer_emotion))\n",
    "\n",
    "print('MER result Average:', t_mer_emotion_avg)\n",
    "print('MER result std:', t_mer_emotion_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "worst-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = '1D_CNN_'+str(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "collect-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp = datetime.datetime.now()\n",
    "run =1\n",
    "algo= '1DCNN/' \n",
    "filename = \"/home/gp/Desktop/MER_arin/12DEAP_RPWE/Results_RPWE_DEAP/\"+algo\n",
    "fname_eeg = filename + 'Run_'+str(run)+'_'+str(time_stamp)+'_all_person_EEG'+'_' +classifier+'_results.csv'\n",
    "fname_eda = filename + 'Run_'+str(run)+'_'+str(time_stamp)+'_all_person_EDA'+'_' +classifier+'_results.csv'\n",
    "fname_resp = filename + 'Run_'+str(run)+'_'+str(time_stamp)+'_all_person_RESP_BELT'+'_' +classifier+'_results.csv'\n",
    "fname_mer = filename + 'Run_'+str(run)+'_'+str(time_stamp)+'_all_person_MER'+'_' +classifier+'_results.csv'\n",
    "\n",
    "column_names = ['Person', 'Video', 'Acc_val', 'F1_val','roc_val', 'mcc_val','Acc_aro',\n",
    "                'F1_aro', 'roc_aro', 'mcc_aro', 'y_act_val', 'y_pred_val', 'y_act_aro', 'y_pred_aro']\n",
    "\n",
    "eeg_emotion = pd.DataFrame(eeg_emotion,columns = column_names)\n",
    "eda_emotion = pd.DataFrame(eda_emotion,columns = column_names)\n",
    "resp_emotion = pd.DataFrame(resp_emotion,columns = column_names)\n",
    "mer_emotion = pd.DataFrame(mer_emotion,columns = column_names)\n",
    "\n",
    "eeg_emotion.to_csv(fname_eeg)\n",
    "eda_emotion.to_csv(fname_eda)\n",
    "resp_emotion.to_csv(fname_resp)\n",
    "mer_emotion.to_csv(fname_mer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-title",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
